{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"Deep Learning I - MNIST.ipynb","provenance":[{"file_id":"1m4D-vCLxmFaU6JAjVBjOsCZJvO9A3T3q","timestamp":1605521789330}],"collapsed_sections":[],"authorship_tag":"ABX9TyNfA59jyDCpGtdPO3/1vjfc"},"kernelspec":{"name":"python3","display_name":"Python 3"},"accelerator":"GPU"},"cells":[{"cell_type":"markdown","metadata":{"id":"NQLuFD-ZqI9e"},"source":["#**ONCODE Masterclass: Introduction to machine learning in cancer genomics**\n","##November 18th, 2020\n","##**Deep Learning 1: Image Classification with a Convolutional Neural Network (CNN)**"]},{"cell_type":"markdown","metadata":{"id":"ykZRQCE4cH_y"},"source":["<img src='https://drive.google.com/uc?id=1gQU3ywndM16loOCb4k4AGklgXu0-yBwv'>"]},{"cell_type":"markdown","metadata":{"id":"ADP5AaAIx9yg"},"source":["##Introduction for absolute beginners: main concepts in deep learning\n","Deep learning is a class of machine learning algorithms inspired by the structure and function of the brain. At the basic level is the perceptron, the mathematical representation of a biological neuron. Just like in the human cortex, there can be several layers of interconnected perceptrons. Input values get passed through this “network” of hidden layers until they eventually converge to the output layer.\n","<center> \n","<img src='https://drive.google.com/uc?id=1YKTC1-wasZywRT6hXCLyBMw8qgrKXRHf' width=\"450\" height=\"220\"/>\n","</center>\n","\n","**Weights** and **biases** and are learned parameters of a perceptron model. **Weights** control the signal (or the strength of the connection) between two neurons.  In other words, a weight decides how much influence the input will have on the output.\n","\n","An **activation function** (sigmoid on the above figure) acts as a mathematical ‘gateway’ which receives the input and calculates a weighted sum with added bias to determine if the node should fire or not. This allows some connections to become stronger, causing new connections to appear, or weaker, causing connections to be eliminated.\n","\n","**Biases** allow you to shift the activation function to the left or right, which may be critical for successful learning.\n","<center> \n","<img src='https://drive.google.com/uc?id=1UTyxjy_aTukY13SmgHQiYGxIVsQGnQ8d' width=\"200\" height=\"80\"/>\n","</center>\n","\n","The output of the network is computed by multiplying the input (x) by the weight (w0) and passing the result through some kind of activation function (e.g. a sigmoid function.)\n","Here is the function that this network computes, for various values of w0:\n","<center> \n","<img src='https://drive.google.com/uc?id=1QwjY10MYcxUX0UH0vvy87IbviNl-ricV' width=\"460\" height=\"340\"/>\n","</center>\n","\n","Changing the weight w0 essentially changes the \"steepness\" of the sigmoid. That's useful, but what if you wanted the network to output 0 when x is 2? Just changing the steepness of the sigmoid won't really work -- you want to be able to shift the entire curve to the right.\n","\n","That's exactly what the bias allows you to do. If we add a bias to that network, like so:\n","<center> \n","<img src='https://drive.google.com/uc?id=1dq-UZIOvqTY6UGPz4xhltbvbhOjBdgFQ' width=\"200\" height=\"150\"/>\n","</center>\n","\n","...then the output of the network becomes sig(w0*x + w1*1.0). Here is what the output of the network looks like for various values of w1:\n","\n","<center> \n","<img src='https://drive.google.com/uc?id=1SWAGE5wFFv_hDww9zF-MFPODiAOAQFmb' width=\"460\" height=\"340\"/>\n","</center>\n","\n","Having a weight of -5 for w1 shifts the curve to the right, which allows us to have a network that outputs 0 when x is 2.\n","\n","In a regular neural network, neurons are fully-connected (each layer have full connections to all activations in the previous layer) and make up multiple layers.\n","\n","<center> \n","<img src='https://drive.google.com/uc?id=1HYUFSGpX4pCMykKIq8p8-qyoseWk_yYl' width=\"430\" height=\"220\"/>\n","</center>\n","\n","**How does the model learn the parameters?**\n","\n","<center> \n","<img src='https://drive.google.com/uc?id=1TC2tUm7kdadsz_Pc-dvA8SlAZP6eXL3p' width=\"430\" height=\"270\"/>\n","</center>\n","\n","Training our deep learning model means that it's learning the values of parameters (weights wij and biases bj) in an iterative process when the information is going forward and back.\n","\n","**Forwardpropagation** occurs when the network is exposed to a training data sample which 'crosses' the entire neural network for its prediction (label) to be calculated. \n","That is, passing the input data through the network in such a way that all the neurons apply their transformation to the information they receive from the neurons of the previous layer and sending it to the neurons of the next layer. When the data has crossed all the layers, and all of the neurons have made their calculations, the final layer will be reached with a result of label prediction for the input example.\n","\n","Next, a **loss function** is used to estimate the loss (or error) and to compare and measure how good/bad our prediction result was in relation to the correct result (remember that we are in a supervised learning environment and we have the label that tells us the expected value). Ideally, we want our cost to be zero, that is, without divergence between estimated and expected value. Therefore, as the model is being trained, the weights of the interconnections of the neurons will gradually be adjusted until good predictions are obtained.\n","\n","Once the loss has been calculated, this information is propagated backwards. Hence, its name: **backpropagation**. Starting from the output layer, that loss information propagates to all the neurons in the hidden layer that contribute directly to the output. However, the neurons of the hidden layer only receive a fraction of the total signal of the loss, based on the relative contribution that each neuron has contributed to the original output. This process is repeated, layer by layer, until all the neurons in the network have received a loss signal that describes their relative contribution to the total loss.\n","\n","The deep learning model wants to learn weights and biases that minimize the loss function.\n","\n","**Neural Network vs. Deep Learning model**\n","\n","Deep learning models are deep neural networks with multiple hidden layers and nodes in each hidden layer. (Typically, if the model has more than 2 hidden layers it's called 'Deep learning')\n","\n","**But why to choose Deep Learning instead of conventional machine learning algorithms?**\n","\n","When dealing with large input data sizes with a long list of input values, machine learning algorithms typically require some feature selection prior to model training. The main advantage of deep learning models is that they do not necessarily need structured data and pre-obtained/selected features to classify the data. Deep learning models send the input through different layers of the network, with each network layer hierarchically defining specific features of the original input data.\n","<center> \n","<img src='https://drive.google.com/uc?id=10mZ4aCmWrv56ymrPQI4llK_F4Nn3-JiX' width=\"490\" height=\"300\"/>\n","</center>\n","\n","Moreover, deep learning models perform better in so-called 'big data' conditions, as they are well suited to learn complex feature patterns from large datasets and perform with higher accuracy on certain tasks (e.g.: image recognition/classification, speech recognition).\n","\n","<center> \n","<img src='https://drive.google.com/uc?id=12t2HoroX8Jf02a6IxsGzO-lzoWrpQ61T' width=\"450\" height=\"300\"/><br>copyright: Andrew Ng</br>\n","</center> \n","\n","## What are Convolutional Neural Networks (CNNs)?\n","\n","D. H. Hubel and T. N. Wiesel proposed an explanation for the way in which mammals visually perceive the world around them using a layered architecture of neurons in the brain. In their hypothesis, within the visual cortex, complex functional responses generated by “complex cells” are constructed from more simplistic responses from “simple cells’. For instances, simple cells would respond to oriented edges etc, while complex cells will also respond to oriented edges but with a degree of spatial invariances.\n","<center> \n","<img src='https://drive.google.com/uc?id=1026v3vAbACmAmCMIkVT8dh1AQY4t9UtT' width=\"720\" height=\"240\"/>\n","</center> \n","\n","This in turn inspired the architecture of deep convolutional neural networks, by the combination of **local connections, layering** and **spacial invariance (shifting the input signal)**.\n","Convolutional networks have been tremendously successful in practical applications where the input data has grid-like topology (e.g. images).\n","<center> \n","<img src='https://drive.google.com/uc?id=189HShi0OjE2FXoxUdKdDsHS44YNG2_4S' width=\"720\" height=\"320\"/>\n","</center> \n","\n","The CNN is a combination of two basic building blocks:\n","\n","**The Convolution Block** — Consists of the **Convolution Layer** and the **Pooling Layer**. This layer forms the essential component for feature extraction.\n","\n","**The Fully Connected Block** — Consists of a fully connected simple neural network architecture. This layer performs the task of classification based on the input from the convolutional block.\n","\n","**Convolution Layer**: An operation is applied on a particular matrix (the image matrix) using another matrix (usually the filter-matrix). The operation involves multiplying the values of a cell corresponding to a particular row and column, of the image matrix, with the value of the corresponding cell in the filter matrix. \n","So, now, how do we find a particular feature? We simply convolve the ‘filter-matrix’ over the image matrix and constitute another matrix that contain some values.\n","<center> \n","<img src='https://drive.google.com/uc?id=1-7Dd2WdH1-dnQCSt5MHB12P4nC9YeMac' width=\"520\" height=\"300\"/>\n","</center> \n","\n","**Pooling Layer**: This layer performs the process of extracting a particular value from a set of values, usually the max value or the average value of all the values. This reduces the size of the output matrix. \n","For example, for MAX-POOLING, we take in the max value among all the values of say a 2x2 part of the matrix. Thus, we are actually taking in the values denoting the presence of a feature in that section of the image. In this way we are getting rid of unwanted information regarding the presence of a feature in a particular portion of the image and considering only what is required to know. It is common to periodically insert a Pooling layer in-between successive convolutional blocks in a CNN architecture. Its function is to progressively reduce the spatial size of the representation to reduce the number of parameters and computation in the network."]},{"cell_type":"markdown","metadata":{"id":"mvQJv_e8o76c"},"source":["## Overview of exercises\n","Now we are going to implement a CNN to classify handwritten digits of the MNIST dataset. The labeled dataset consists of 60000 images of size 28x28 = 784 pixels (one gray-scale number) including the corresponding labels from 0,..,9. Each image is normalized such that each pixel takes on values in the range [0,1]. <br>\n","</br>\n","\n","This architecture will be implemented with Keras and TensorFlow. In order to prevent the network from overfitting during learning we implement dropout and data augmentation, i.e. new images are generated from the original ones via rotation, translation and zooming. If we will have time, we can also explore the application of cross-validation.\n","## Loading packages"]},{"cell_type":"code","metadata":{"id":"AIscqIzquNLu","executionInfo":{"status":"ok","timestamp":1605613628193,"user_tz":-60,"elapsed":516,"user":{"displayName":"Alexandra Danyi","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gj39tvW5uCYW0UwNfbyCNimpC__CHrYKtGlc-cEvg=s64","userId":"17961698180830904661"}}},"source":["import itertools\n","import numpy as np\n","import pandas as pd\n","import datetime\n","import matplotlib.pyplot as plt\n","%matplotlib inline\n","\n","from sklearn.metrics import confusion_matrix\n","from sklearn.model_selection import KFold\n","\n","import tensorflow as tf\n","\n","from keras.datasets import mnist\n","from keras.models import Sequential\n","from keras.layers import Dense, Dropout, Activation, Flatten\n","from keras.optimizers import Adam\n","from keras.layers.normalization import BatchNormalization\n","from keras.utils import np_utils, plot_model\n","from keras.layers import Conv2D, MaxPooling2D, ZeroPadding2D, GlobalAveragePooling2D\n","from keras.layers.advanced_activations import LeakyReLU \n","from keras.preprocessing.image import ImageDataGenerator\n","\n","np.random.seed(25)"],"execution_count":26,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"nqrKwQX8wjCp"},"source":["##Load data and have a look at it"]},{"cell_type":"code","metadata":{"id":"4dqYyqJcveEN"},"source":["(X_train, y_train), (X_test, y_test) = mnist.load_data()\n","print(\"X_train original shape\", X_train.shape)\n","print(\"y_train original shape\", y_train.shape)\n","print(\"X_test original shape\", X_test.shape)\n","print(\"y_test original shape\", y_test.shape)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"NIvbjUS1wQHF"},"source":["fig = plt.figure()\n","for i in range(9):\n","  plt.subplot(3,3,i+1)\n","  plt.tight_layout()\n","  plt.imshow(X_train[i], cmap='gray', interpolation='none')\n","  plt.title(\"Digit: {}\".format(y_train[i]))\n","  plt.xticks([])\n","  plt.yticks([])\n","fig"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"5P6a7o0bwz16"},"source":["## Reshaping digit images\n","mnist.load_data() supplies the MNIST digits with structure (number of samples, 28, 28) i.e. with 2 dimensions per example representing a greyscale image in 28x28.\n","\n","However, we are going to work with 'Conv2D' layers in Keras which are designed to handle 3 dimensions per example. They have 4-dimensional inputs and outputs. This covers colour images (number of samples, number of channels, width, height), but more importantly, it covers deeper layers of the network, where each example has become a set of feature maps i.e. (number of samples, number of features, width, height).\n","\n","The greyscale image for MNIST digits input would either need a different CNN layer design (or a parameter to the layer constructor to accept a different shape), or the design could simply use a standard CNN and you must explicitly express the examples as 1-channel images. In Keras, they chose the latter approach, which needs the re-shape."]},{"cell_type":"code","metadata":{"id":"IZ8X2se_weJG"},"source":["X_train = X_train.reshape(X_train.shape[0], 28, 28, 1)\n","X_test = X_test.reshape(X_test.shape[0], 28, 28, 1)\n","\n","X_train = X_train.astype('float32')\n","X_test = X_test.astype('float32')\n","\n","X_train.shape"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"XFL05W3sIexp"},"source":["##Normalization\n","The pixel values of the 28x28 images range from 0 to 255: the background majority close to 0, and those close to 255 representing the digit. Normalizing the input data helps to speed up the training. It reduces the chance of getting stuck in local optima as well, since we're using stochastic gradient descent to find the optimal weights for the network.<br>\n","</br>\n","So let's normalize the pixel values to lie between 0 and 1."]},{"cell_type":"code","metadata":{"id":"G5ue-NPKIhoU"},"source":["X_train/=255\n","X_test/=255\n","\n","X_train.shape"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"32Rw-z6az3-C"},"source":["##One-hot encoding of image labels\n","\n","Our model will output a probability distribution across all 0-9 numbers in a vector, therefore we will need to convert the labels using one hot encoding to represent the numbers in a vector:\n"]},{"cell_type":"code","metadata":{"id":"-Fvb4oR7z2Gk"},"source":["number_of_classes = 10\n","\n","Y_train = np_utils.to_categorical(y_train, number_of_classes)\n","Y_test = np_utils.to_categorical(y_test, number_of_classes)\n","\n","y_train[0], Y_train[0]"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"I1rZNBlT1Lv0"},"source":["##Building a basic CNN model\n","\n","**Batch size** defines the number of samples that will be propagated through the network. \n","\n","One **Epoch** is defined when the entire dataset is passed forward and backward through the neural network only ONCE. Typically, more then one epoch is used as passing the entire dataset through a neural network once is not enough. Keep in mind that we are using a limited dataset (however big it is, it's just a sample from a population) and we are often optimizing  thousands or hunderds of thousands of parameters in a deep learning model in an iterative process. So, updating the weights with a single pass or one epoch is not enough.\n","\n","**Softmax function** turns logits (numeric output of the last linear layer of a multi-class classification neural network) into probabilities by taking the exponents of each output and then normalizing each number by the sum of those exponents so the entire output vector adds up to one — all probabilities should add up to one."]},{"cell_type":"code","metadata":{"id":"JkNVISBq1Gw1","executionInfo":{"status":"ok","timestamp":1605613452493,"user_tz":-60,"elapsed":628,"user":{"displayName":"Alexandra Danyi","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gj39tvW5uCYW0UwNfbyCNimpC__CHrYKtGlc-cEvg=s64","userId":"17961698180830904661"}}},"source":["def build_cnn():\n","    # 1. Convolution\n","    # 2. Activation\n","    # 3. Pooling\n","    # Repeat Steps 1,2,3 for adding more hidden layers\n","    model = Sequential()\n","\n","    model.add(Conv2D(32, (3, 3), input_shape=(28,28,1)))\n","    model.add(Activation('relu'))\n","    model.add(Conv2D(32, (3, 3)))\n","    model.add(Activation('relu'))\n","    model.add(MaxPooling2D(pool_size=(2,2)))\n","\n","    model.add(Conv2D(64,(3, 3)))\n","    model.add(Activation('relu'))\n","    model.add(Conv2D(64, (3, 3)))\n","    model.add(Activation('relu'))\n","    model.add(MaxPooling2D(pool_size=(2,2)))\n","\n","    model.add(Flatten())\n","\n","    # Fully connected block\n","    model.add(Dense(512))\n","    model.add(Activation('relu'))\n","    model.add(Dropout(0.2))\n","    model.add(Dense(10))\n","\n","    model.add(Activation('softmax'))\n","\n","    return model"],"execution_count":9,"outputs":[]},{"cell_type":"code","metadata":{"id":"aPae1J-F_w_M","executionInfo":{"status":"ok","timestamp":1605613460201,"user_tz":-60,"elapsed":5907,"user":{"displayName":"Alexandra Danyi","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gj39tvW5uCYW0UwNfbyCNimpC__CHrYKtGlc-cEvg=s64","userId":"17961698180830904661"}}},"source":["model = build_cnn()"],"execution_count":10,"outputs":[]},{"cell_type":"code","metadata":{"id":"OUad1cBs1c-R"},"source":["model.summary()"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"itH9QqKv1edC"},"source":["plot_model(model, to_file='model.png', show_shapes = True, show_layer_names = True)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"XrIgfzlZuVzs"},"source":["Now we need to compile our model and define a few last bits, namely: the optimizer of choice and the loss function that we are going to use.\n","\n","**ADAM optimizer** is an adaptive learning rate method, which means that it computes individual learning rates for different parameters. The amount that the weights are updated during training is referred to as the step size or the “learning rate”. The learning rate is a configurable hyperparameter used in the training of neural networks that has a small positive value, often in the range between 0.0 and 1.0.\n","\n","We are going to use the **Categorical crossentropy** loss. If we use this loss, we will train a CNN to output a probability over the classes for each image. This loss is used for multi-class classification."]},{"cell_type":"code","metadata":{"id":"U0fAZPFa2HZh","executionInfo":{"status":"ok","timestamp":1605613473143,"user_tz":-60,"elapsed":495,"user":{"displayName":"Alexandra Danyi","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gj39tvW5uCYW0UwNfbyCNimpC__CHrYKtGlc-cEvg=s64","userId":"17961698180830904661"}}},"source":["model.compile(loss='categorical_crossentropy', optimizer=Adam(), metrics=['accuracy'])"],"execution_count":14,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"FXEK6Ye2jSsK"},"source":["We have to divide the current training set further into the final training set and a validation set."]},{"cell_type":"code","metadata":{"id":"lxtZ7Por2yQC","executionInfo":{"status":"ok","timestamp":1605613474194,"user_tz":-60,"elapsed":458,"user":{"displayName":"Alexandra Danyi","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gj39tvW5uCYW0UwNfbyCNimpC__CHrYKtGlc-cEvg=s64","userId":"17961698180830904661"}}},"source":["size = int(len(X_train) * 0.8)\n","\n","train_x, val_x = X_train[:size], X_train[size:]\n","train_y, val_y = Y_train[:size], Y_train[size:]"],"execution_count":15,"outputs":[]},{"cell_type":"code","metadata":{"id":"XVVRFuKC2zEX"},"source":["history_basic = model.fit(train_x, train_y, batch_size=128, epochs=5, validation_data=(val_x, val_y))\n"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"_mrXl-_Y3wyb"},"source":["score = model.evaluate(X_test, Y_test)\n","print()\n","print('Test accuracy: ', score[1])"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"Nom_4kPO_L6b"},"source":["history_basic.history.keys() "],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"B-UsSyC34tpo"},"source":["fig = plt.figure()\n","plt.subplot(2,1,1)\n","plt.plot(history_basic.history['accuracy'])\n","plt.plot(history_basic.history['val_accuracy'])\n","plt.title('model accuracy')\n","plt.ylabel('accuracy')\n","plt.xlabel('epoch')\n","plt.legend(['train', 'test'], loc='lower right')\n","\n","plt.subplot(2,1,2)\n","plt.plot(history_basic.history['loss'])\n","plt.plot(history_basic.history['val_loss'])\n","plt.title('model loss')\n","plt.ylabel('loss')\n","plt.xlabel('epoch')\n","plt.legend(['train', 'test'], loc='upper right')\n","\n","plt.tight_layout()"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"97x6lZGaBFYo"},"source":["And finally we plot the confusion matrix:"]},{"cell_type":"code","metadata":{"id":"segQX2JBCA1r"},"source":["y_pred = model.predict(X_test)\n","Y_pred_classes = np.argmax(y_pred,axis=1) \n","Y_true = np.argmax(Y_test,axis=1)\n","\n","confusion_mtx = confusion_matrix(Y_true, Y_pred_classes) \n","\n","def plot_confusion_matrix(cm, classes,\n","                          normalize=False,\n","                          title='Confusion matrix',\n","                          cmap=plt.cm.Blues):\n","    plt.figure(figsize = (5,5))\n","    plt.imshow(cm, interpolation='nearest', cmap=cmap)\n","    plt.title(title)\n","    plt.colorbar()\n","    tick_marks = np.arange(len(classes))\n","    plt.xticks(tick_marks, classes, rotation=90)\n","    plt.yticks(tick_marks, classes)\n","    if normalize:\n","        cm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n","\n","    thresh = cm.max() / 2.\n","    for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n","        plt.text(j, i, cm[i, j],\n","                 horizontalalignment=\"center\",\n","                 color=\"white\" if cm[i, j] > thresh else \"black\")\n","    plt.tight_layout()\n","    plt.ylabel('True label')\n","    plt.xlabel('Predicted label')\n","\n","plot_confusion_matrix(confusion_mtx, classes = [0,1,2,3,4,5,6,7,8,9]) \n","plt.show()"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"R3XLTV-E4lDu"},"source":["##The next level: enhancing the training set with data augmentation"]},{"cell_type":"code","metadata":{"id":"M-CA7y3M45kP","executionInfo":{"status":"ok","timestamp":1605613511176,"user_tz":-60,"elapsed":489,"user":{"displayName":"Alexandra Danyi","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gj39tvW5uCYW0UwNfbyCNimpC__CHrYKtGlc-cEvg=s64","userId":"17961698180830904661"}}},"source":["# rotations, translations, zoom\n","gen = ImageDataGenerator(rotation_range=8, width_shift_range=0.08, shear_range=0.3,\n","                         height_shift_range=0.08, zoom_range=0.08)\n","# get transformed images\n","test_gen = ImageDataGenerator()\n","train_generator = gen.flow(X_train, Y_train, batch_size=64)\n","test_generator = test_gen.flow(X_test, Y_test, batch_size=64)"],"execution_count":21,"outputs":[]},{"cell_type":"code","metadata":{"id":"SU3y5KAS8GDT"},"source":["history_augmented = model.fit_generator(train_generator, steps_per_epoch=60000//64, epochs=5, \n","                    validation_data=test_generator, validation_steps=10000//64)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"6wUVWK7X8jbv"},"source":["score = model.evaluate(X_test, Y_test)\n","print()\n","print('Test accuracy: ', score[1])"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"YWxIwNhJEDym"},"source":["fig = plt.figure()\n","plt.subplot(2,1,1)\n","plt.plot(history_augmented.history['accuracy'])\n","plt.plot(history_augmented.history['val_accuracy'])\n","plt.title('model accuracy')\n","plt.ylabel('accuracy')\n","plt.xlabel('epoch')\n","plt.legend(['train', 'test'], loc='lower right')\n","\n","plt.subplot(2,1,2)\n","plt.plot(history_augmented.history['loss'])\n","plt.plot(history_augmented.history['val_loss'])\n","plt.title('model loss')\n","plt.ylabel('loss')\n","plt.xlabel('epoch')\n","plt.legend(['train', 'test'], loc='upper right')\n","\n","plt.tight_layout()"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"2zR9nSZ6EXz7"},"source":["y_pred = model.predict(X_test)\n","Y_pred_classes = np.argmax(y_pred,axis=1) \n","Y_true = np.argmax(Y_test,axis=1)\n","\n","confusion_mtx = confusion_matrix(Y_true, Y_pred_classes) \n","\n","def plot_confusion_matrix(cm, classes,\n","                          normalize=False,\n","                          title='Confusion matrix',\n","                          cmap=plt.cm.Blues):\n","    plt.figure(figsize = (5,5))\n","    plt.imshow(cm, interpolation='nearest', cmap=cmap)\n","    plt.title(title)\n","    plt.colorbar()\n","    tick_marks = np.arange(len(classes))\n","    plt.xticks(tick_marks, classes, rotation=90)\n","    plt.yticks(tick_marks, classes)\n","    if normalize:\n","        cm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n","\n","    thresh = cm.max() / 2.\n","    for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n","        plt.text(j, i, cm[i, j],\n","                 horizontalalignment=\"center\",\n","                 color=\"white\" if cm[i, j] > thresh else \"black\")\n","    plt.tight_layout()\n","    plt.ylabel('True label')\n","    plt.xlabel('Predicted label')\n","\n","plot_confusion_matrix(confusion_mtx, classes = [0,1,2,3,4,5,6,7,8,9]) \n","plt.show()"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"gWjrSooT8fD4"},"source":["## +1 Exercise: using K-Fold cross-validation"]},{"cell_type":"code","metadata":{"id":"u6AzmwyS8UTG"},"source":["num_folds = 10\n","# per-fold metric containers\n","acc_per_fold = []\n","loss_per_fold = []\n","\n","inputs = np.concatenate((X_train, X_test), axis=0)\n","targets = np.concatenate((y_train, y_test), axis=0)\n","\n","fold = 1\n","kf = KFold(n_splits=num_folds)\n","for train, test in kf.split(inputs, targets):\n","    model_fold = build_cnn()\n","    model_fold.compile(loss='categorical_crossentropy', optimizer=Adam(), metrics=['accuracy'])\n","\n","    y_train_fold = targets[train]\n","    y_test_fold = targets[test]\n","\n","    number_of_classes = 10\n","    Y_train_fold = np_utils.to_categorical(y_train_fold, number_of_classes)\n","    Y_test_fold = np_utils.to_categorical(y_test_fold, number_of_classes)\n","\n","    print(f'Training for fold {fold} ...')\n","\n","    X_train_fold = inputs[train]\n","    X_test_fold = inputs[test]\n","\n","    size = int(len(inputs[train]) * 0.8)\n","\n","    train_x_fold, val_x_fold = X_train_fold[:size], X_train_fold[size:]\n","    train_y_fold, val_y_fold = Y_train_fold[:size], Y_train_fold[size:]\n","\n","    history_fold = model_fold.fit(train_x_fold, train_y_fold, batch_size=128, epochs=5, validation_data=(val_x_fold, val_y_fold))\n","  \n","    # Generate generalization metrics\n","    scores = model_fold.evaluate(X_test_fold, Y_test_fold, verbose=0)\n","    print(f'Score for fold {fold}: {model_fold.metrics_names[0]} of {scores[0]}; {model_fold.metrics_names[1]} of {scores[1]*100}%')\n","    acc_per_fold.append(scores[1] * 100)\n","    loss_per_fold.append(scores[0])\n","\n","    fold = fold + 1"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"b02XazEC9A-Q"},"source":["print('Score per fold')\n","for i in range(0, len(acc_per_fold)):\n","  print(f'> Fold {i+1} - Loss: {loss_per_fold[i]} - Accuracy: {acc_per_fold[i]}%')\n","print('Average scores for all folds:')\n","print(f'> Accuracy: {np.mean(acc_per_fold)} (+- {np.std(acc_per_fold)})')\n","print(f'> Loss: {np.mean(loss_per_fold)}')"],"execution_count":null,"outputs":[]}]}